{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffadd77b-c093-4b29-9ffa-8a11eec815d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import torch.nn.functional as F\n",
    "import io\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "from IPython.display import display, Image, update_display, HTML\n",
    "from fastprogress.fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "688ea896-423f-4acd-846d-8a4e094176b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config: pass\n",
    "config = Config()\n",
    "config.batch_size = 2\n",
    "config.samples_per_file = 4\n",
    "config.num_workers = 12\n",
    "config.grad_accum_steps = 1\n",
    "config.plot_update = 128\n",
    "config.patience = 64\n",
    "config.min_lr = 1e-7\n",
    "config.max_lr = 3e-5\n",
    "config.warmup_steps = 50000\n",
    "config.weight_decay = 0.\n",
    "config.epochs = 300\n",
    "config.Ï• = 1.\n",
    "\n",
    "config.audio_length = 2**16\n",
    "config.channels=2\n",
    "config.J = 3\n",
    "config.Ne = None\n",
    "config.Nd = 512\n",
    "config.latent_dim = 64\n",
    "config.latent_bits = 8\n",
    "config.lightweight_encode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcd09179-fae0-44f0-876d-1516642171fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef278860dc99497fb3410d79d05b4fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420bd798197a4cb98d9563df738d5d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee609c50b5d4ba89ee7522285df7398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6ffe5234a242319bb6a403a15200fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de365d1c00d344678bcd76b8aca50f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaa7eb3ae0745c4a068a46b2ef20675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b849c05ba4d442b98aa1195990ef9a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92dde6efa2f4484b1346019517e18ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fc7fe643f54063991c507d65a876c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "train_dataset = load_dataset(\"danjacobellis/musdb18HQ\", split=\"train\")\n",
    "valid_dataset = load_dataset(\"danjacobellis/musdb18HQ\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567820c7-803a-484a-8352-52fadaaaeb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = config.audio_length\n",
    "C = config.channels\n",
    "N = config.samples_per_file\n",
    "crop = torchvision.transforms.RandomCrop((1,L))\n",
    "def collate_fn(batch):\n",
    "    B = N*len(batch)\n",
    "    x = torch.zeros( (B, C, 1, L), dtype=torch.float32)\n",
    "    i_sample = 0\n",
    "    for file in batch:\n",
    "        audio,fs = torchaudio.load(file['audio']['bytes'])\n",
    "        audio = audio.unsqueeze(1)\n",
    "        for _ in range(N):\n",
    "            x[i_sample,:,:,:] = crop(audio)\n",
    "            i_sample+=1\n",
    "    return x.squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd9489e9-7a2e-4f4a-a73e-721b247557c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_valid = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=12,\n",
    "    drop_last=True,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67d05c7b-1705-4c36-bfce-868de7077c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.1 ms, sys: 101 ms, total: 121 ms\n",
      "Wall time: 909 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "valid_batch = next(iter(dataloader_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48318281-4402-467a-aa68-f35d66841fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import einops\n",
    "from pytorch_wavelets import DWTForward, DWTInverse\n",
    "import diffusers.models.autoencoders as autoencoders \n",
    "\n",
    "class Round(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Round, self).__init__()\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            noise = torch.rand_like(x) - 0.5\n",
    "            return x + noise\n",
    "        else:\n",
    "            return torch.round(x)\n",
    "        \n",
    "class AudioWalloc(nn.Module):\n",
    "    def __init__(self, channels, J, Ne, Nd, latent_dim, latent_bits, lightweight_encode):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.J = J\n",
    "        self.freq_bands = 4**J\n",
    "        self.Ne = Ne\n",
    "        self.Nd = Nd\n",
    "        self.latent_dim = latent_dim\n",
    "        self.latent_bits = latent_bits\n",
    "        self.latent_max = 2**(latent_bits-1)-1+0.5-1e-3\n",
    "        self.wt  = DWTForward(J=1, mode='periodization', wave='bior4.4')\n",
    "        self.iwt = DWTInverse(mode='periodization', wave='bior4.4')\n",
    "        self.clamp = torch.nn.Hardtanh(min_val=-0.5, max_val=0.5)\n",
    "\n",
    "        entropy_bottleneck = [\n",
    "            torch.nn.Hardtanh(min_val=-self.latent_max, max_val=self.latent_max),\n",
    "            Round()\n",
    "        ]\n",
    "\n",
    "        if lightweight_encode:\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=self.channels * self.freq_bands,\n",
    "                    out_channels=self.latent_dim,\n",
    "                    kernel_size=(1, 1),\n",
    "                    stride=(1, 1),\n",
    "                    padding=(0, 0),\n",
    "                ),\n",
    "                *entropy_bottleneck\n",
    "            )\n",
    "        else:\n",
    "            self.encoder = nn.Sequential(\n",
    "                autoencoders.autoencoder_oobleck.OobleckEncoder(\n",
    "                    encoder_hidden_size=self.latent_dim,\n",
    "                    audio_channels=self.channels,\n",
    "                    downsampling_ratios=[2, 4, 4, 8, 8],\n",
    "                    channel_multiples=[1, 2, 4, 8, 16]\n",
    "                ),\n",
    "                *entropy_bottleneck\n",
    "            )\n",
    "            \n",
    "        self.decoder = nn.Sequential(\n",
    "                autoencoders.autoencoder_oobleck.OobleckDecoder(\n",
    "                    channels=128,\n",
    "                    input_channels=self.latent_dim,\n",
    "                    audio_channels=self.channels,\n",
    "                    upsampling_ratios=[8, 8, 4, 4, 2],\n",
    "                    channel_multiples=[1, 2, 4, 8, 16],\n",
    "                )\n",
    "            )\n",
    "        \n",
    "    def analysis_one_level(self,x):\n",
    "        L, H = self.wt(x)\n",
    "        X = torch.cat([L.unsqueeze(2),H[0]],dim=2)\n",
    "        X = einops.rearrange(X, 'b c f h w -> b (c f) h w')\n",
    "        return X\n",
    "    \n",
    "    def wavelet_analysis(self,x,J=3):\n",
    "        for _ in range(J):\n",
    "            x = self.analysis_one_level(x)\n",
    "        return x\n",
    "    \n",
    "    def synthesis_one_level(self,X):\n",
    "        X = einops.rearrange(X, 'b (c f) h w -> b c f h w', f=4)\n",
    "        L, H = torch.split(X, [1, 3], dim=2)\n",
    "        L = L.squeeze(2)\n",
    "        H = [H]\n",
    "        y = self.iwt((L, H))\n",
    "        return y\n",
    "    \n",
    "    def wavelet_synthesis(self,x,J=3):\n",
    "        for _ in range(J):\n",
    "            x = self.synthesis_one_level(x)\n",
    "        return x\n",
    "            \n",
    "    # def forward(self, x):\n",
    "    #     X = self.wavelet_analysis(x,J=self.J)\n",
    "    #     Y = self.encoder(X)\n",
    "    #     X_hat = self.decoder(Y)\n",
    "    #     x_hat = self.wavelet_synthesis(X_hat,J=self.J)\n",
    "    #     tf_loss = F.mse_loss( X.abs(), X_hat.abs() )\n",
    "    #     return self.clamp(x_hat), F.mse_loss(x,x_hat), tf_loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        Y = self.encoder(x)\n",
    "        x_hat = self.decoder(Y)\n",
    "        return self.clamp(x_hat), F.mse_loss(x,x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73684401-7c03-4368-9ea1-a1837cfac336",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'codec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m codec \u001b[38;5;241m=\u001b[39m \u001b[43mAudioWalloc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mJ\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJ\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlatent_bits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatent_bits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlightweight_encode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightweight_encode\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(\n\u001b[1;32m     12\u001b[0m     params\u001b[38;5;241m=\u001b[39mcodec\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m     13\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m     14\u001b[0m     lr \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mmin_lr\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m codec\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e6\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mAudioWalloc.__init__\u001b[0;34m(self, channels, J, Ne, Nd, latent_dim, latent_bits, lightweight_encode)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     40\u001b[0m         nn\u001b[38;5;241m.\u001b[39mConv2d(\n\u001b[1;32m     41\u001b[0m             in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannels \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfreq_bands,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;241m*\u001b[39mentropy_bottleneck\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     51\u001b[0m         autoencoders\u001b[38;5;241m.\u001b[39mautoencoder_oobleck\u001b[38;5;241m.\u001b[39mOobleckEncoder(\n\u001b[0;32m---> 52\u001b[0m             encoder_hidden_size\u001b[38;5;241m=\u001b[39m\u001b[43mcodec\u001b[49m\u001b[38;5;241m.\u001b[39mlatent_dim,\n\u001b[1;32m     53\u001b[0m             audio_channels\u001b[38;5;241m=\u001b[39mcodec\u001b[38;5;241m.\u001b[39mchannels,\n\u001b[1;32m     54\u001b[0m             downsampling_ratios\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m],\n\u001b[1;32m     55\u001b[0m             channel_multiples\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m]\n\u001b[1;32m     56\u001b[0m         ),\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;241m*\u001b[39mentropy_bottleneck\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m     61\u001b[0m         autoencoders\u001b[38;5;241m.\u001b[39mautoencoder_oobleck\u001b[38;5;241m.\u001b[39mOobleckDecoder(\n\u001b[1;32m     62\u001b[0m             channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'codec' is not defined"
     ]
    }
   ],
   "source": [
    "codec = AudioWalloc(\n",
    "    channels=config.channels,\n",
    "    J=config.J,\n",
    "    Ne=config.Ne,\n",
    "    Nd=config.Nd,\n",
    "    latent_dim=config.latent_dim,\n",
    "    latent_bits=config.latent_bits,\n",
    "    lightweight_encode=config.lightweight_encode\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=codec.parameters(),\n",
    "    weight_decay=0.0,\n",
    "    lr = config.min_lr\n",
    ")\n",
    "\n",
    "sum(p.numel() for p in codec.parameters())/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d7ffda-ecb2-45e1-badc-3b1ab32e5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minus_cosine_warmup(i_step):\n",
    "    scale = 0.5 * (np.log10(config.max_lr) - np.log10(config.min_lr))\n",
    "    angle =  np.pi * i_step / (config.warmup_steps//config.plot_update)\n",
    "    log_lr = np.log10(config.min_lr) + scale * (1 - np.cos(angle))\n",
    "    lr = 10 ** log_lr\n",
    "    return lr/config.min_lr\n",
    "    \n",
    "warmup = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lr_lambda = lambda i_step: minus_cosine_warmup(i_step)\n",
    ")\n",
    "\n",
    "reduce_plateau = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    factor=0.98,\n",
    "    patience=config.patience,\n",
    "    threshold=1e-5,\n",
    "    min_lr=config.min_lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee681a81-37a3-4f2d-8069-dad9f9dd7682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/300 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/250 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [2048, 64, 7], expected input[8, 128, 32] to have 64 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(progress_bar(dataloader, parent\u001b[38;5;241m=\u001b[39mmb)):\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 25\u001b[0m     _, mse_loss \u001b[38;5;241m=\u001b[39m \u001b[43mcodec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     dist_loss \u001b[38;5;241m=\u001b[39m mse_loss \u001b[38;5;241m+\u001b[39m config\u001b[38;5;241m.\u001b[39mÏ•\u001b[38;5;241m*\u001b[39mtf_loss\n\u001b[1;32m     28\u001b[0m     dist_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mlog10(dist_loss\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 104\u001b[0m, in \u001b[0;36mAudioWalloc.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    103\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m--> 104\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclamp(x_hat), F\u001b[38;5;241m.\u001b[39mmse_loss(x,x_hat)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/diffusers/models/autoencoders/autoencoder_oobleck.py:283\u001b[0m, in \u001b[0;36mOobleckDecoder.forward\u001b[0;34m(self, hidden_state)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state):\n\u001b[0;32m--> 283\u001b[0m     hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock:\n\u001b[1;32m    286\u001b[0m         hidden_state \u001b[38;5;241m=\u001b[39m layer(hidden_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [2048, 64, 7], expected input[8, 128, 32] to have 64 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", message=\"Truncated File Read\", category=UserWarning, module=\"PIL.TiffImagePlugin\")\n",
    "dist_losses, rate_losses = [], []\n",
    "learning_rates = [optimizer.param_groups[0]['lr']]\n",
    "img_displays = []\n",
    "text_display = None\n",
    "codec.train()\n",
    "optimizer.zero_grad()\n",
    "mb = master_bar(range(config.epochs))\n",
    "mb.names = ['Distortion Loss', 'Smoothed']\n",
    "i_step = 0\n",
    "for i_epoch in mb:\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "   \n",
    "    for i, batch in enumerate(progress_bar(dataloader, parent=mb)):\n",
    "    \n",
    "        x = batch.to(device)\n",
    "\n",
    "        _, mse_loss = codec(x)\n",
    "\n",
    "        dist_loss = mse_loss + config.Ï•*tf_loss\n",
    "        dist_losses.append(np.log10(dist_loss.item()))\n",
    "        loss = dist_loss\n",
    "        loss.backward()\n",
    "        if (i + 1) % config.grad_accum_steps == 0: \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # plotting and lr scheduler\n",
    "        if len(dist_losses) % config.plot_update == 0:\n",
    "            plot_n = len(dist_losses) // config.plot_update\n",
    "            smoothed_x = (0.5+torch.arange(plot_n)) * config.plot_update\n",
    "            smoothed_y = torch.tensor(dist_losses).reshape(plot_n, -1).mean(dim=1)\n",
    "            dist_x = range(len(dist_losses))\n",
    "            dist_y = dist_losses\n",
    "            mb.update_graph([[dist_x, dist_y],[smoothed_x, smoothed_y]])\n",
    "            mb.child.comment = f'loss {smoothed_y[-1]:.4g}; lr {learning_rates[-1]:.4g}'\n",
    "\n",
    "            # lr scheduler\n",
    "            if i_step < config.warmup_steps:\n",
    "                warmup.step()\n",
    "            else:\n",
    "                reduce_plateau.step(smoothed_y[-1])\n",
    "            learning_rates.append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                codec.eval()\n",
    "                y_valid, _, _ = codec(valid_batch)\n",
    "                codec.train()\n",
    "            \n",
    "            # for img_idx, img in enumerate(y_valid):\n",
    "            #     buffer = io.BytesIO()\n",
    "            #     ToPILImage()(img + 0.5).save(buffer, format=\"PNG\")\n",
    "            #     # ToPILImage()(img + 0.5).save(f\"video/{img_idx}_{i_epoch}_{i}.png\")\n",
    "            #     buffer.seek(0)\n",
    "            #     if len(img_displays) <= img_idx:\n",
    "            #         img_displays.append(display(Image(buffer.read()), display_id=True))\n",
    "            #     else:\n",
    "            #         update_display(Image(buffer.read()), display_id=img_displays[img_idx].display_id)\n",
    "        i_step+=1\n",
    "        \n",
    "    torch.save({\n",
    "        'model_state_dict': codec.state_dict(),\n",
    "        'i_epoch': i_epoch,\n",
    "        'learning_rates': learning_rates,\n",
    "        'dist_losses': dist_losses,\n",
    "        'config': config\n",
    "    }, f\"log_{device}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c141ce5-9b7f-4941-9474-ea41410a0921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "display(HTML(mb.main_bar.progress))\n",
    "display(HTML(mb.child.progress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29ec52-ae57-4b4f-a89a-d686a8975349",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'model_state_dict': codec.state_dict(),\n",
    "    'i_epoch': i_epoch,\n",
    "    'learning_rates': learning_rates,\n",
    "    'dist_losses': dist_losses,\n",
    "    'config': config\n",
    "}, \"../../hf/walloc/v0.12.1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df09bf28-c404-4a6a-b60d-832e89bc881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(smoothed_x,smoothed_y)\n",
    "plt.ylim([-2.5,-2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752b605-0373-4149-913c-704d1a7f67b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_idx, img in enumerate(y_valid):\n",
    "    display(ToPILImage()(img + 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb18b4b3-fd2a-4b47-aed4-57a48040e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    X = codec.wavelet_analysis(valid_batch,codec.J)\n",
    "    Z = codec.encoder[:1](X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c538158-beb2-4a78-b58d-b611b7284a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "bytes = Z.round().to(torch.int8).detach().cpu().numpy().tobytes()\n",
    "print(valid_batch.numel()/len(bytes))\n",
    "print(valid_batch.numel()/len(zlib.compress(bytes,level=9)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b66437-aff4-4fce-8c04-15a133ac95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Z.to(\"cpu\").flatten().numpy(), density=True,range=(-8,8),bins=100);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
